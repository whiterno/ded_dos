/*----------------------------------------------------------------------------
 *
 *						ПРИМЕР ДЕМОНСТРИРУЕТ ЭФФЕКТИВНОСТЬ
 *			ИСПОЛЬЗОВАНИЯ "СКВОЗНОЙ"ЗАГРУЗКИ ДАННЫХ В L1-КЭШ, МИНУЯ L2
 *			==========================================================
 *
 * Build 0x002 10.08.2002
----------------------------------------------------------------------------*/
#define BLOCK1_SIZE	(128*K)				// блок, целиком вмещающийся в L2-кэш,
										// но выходящий за пределы L1-кэша

#define BLOCK2_SIZE	(4*M)				// блок, значительно превосхоядщий
										// L2-кэш в размерах
#define STEP_SIZE	32
#include <DoCPU.h>
#define a _p2

/*----------------------------------------------------------------------------
 *
 *							ТЕСТ БЕЗ ПРЕДВЫБОРКИ
 *												(неоптимизированный вариант)
 *
----------------------------------------------------------------------------*/
float no_prefetch(int *p1, int *p2)
{
	int x = 0;
	int _p2, _p1 = 0;
	
	for(_p2 = 0; _p2 < BLOCK2_SIZE; _p2 += STEP_SIZE)
	{
		//				* * * обрабатываем блок BLOCK1 * * *
		// поскольку он обрабатывается в цикле (имеется ввиду цикл A_BEGIN),
		// желательно, чтобы ничто не вытесняло его из L2-кэша
		x += *(int *)((char *)p1 + _p1); if ((_p1 += 4) > BLOCK1_SIZE) _p1 = 0;

		//				* * * обрабатываем блок BLOCK1 * * *
		// этот блок значительно  превосходит L2-кэш  в  размерах,  поэтому,
		// кэшировать его абсолютно необзятельно - все равно при последующих
		// итерациях цикла нужных данных в кэше не окажется..
		// к тому  же в L2-кэше  уже  содержится  BLOCK1, вытеснять  который
		// нежелательно. Но, уин! Сарынь на  кичку  лапы  и  хвот  плюшевого
		// медведя! Процессор по самостоятельно помещает данные блока BLOCK2
		// в L2-кэш, выбирая самую неоптимальную стратению кэширования...
		x += *(int *)((char *)p2 + a);
		x += *(int *)((char *)p2 + a + 4);
		x += *(int *)((char *)p2 + a + 8);
		x += *(int *)((char *)p2 + a + 12);
		x += *(int *)((char *)p2 + a + 16);
		x += *(int *)((char *)p2 + a + 20);
		x += *(int *)((char *)p2 + a + 24);
		x += *(int *)((char *)p2 + a + 28);
	}
	return x;
}

/*----------------------------------------------------------------------------
 *
 *				ТЕСТ С ПРЕДВЫБОРКОЙ prefetchnta (mem -> L1)
 *												(оптимизированный вариант)
 *
----------------------------------------------------------------------------*/
int have_prefetchnta(int *p1, int *p2)
{
	int x = 0;
	int _p2, _p1 = 0;

	for(_p2 = 0; _p2 < BLOCK2_SIZE; _p2 += STEP_SIZE)
	{
		//				* * * обрабатываем блок BLOCK1 * * *
		// предвыборка в L1-кэш  не  нужна, т.к.  производительность L2-кэша
		// (где и находится  данный  блок)  вполне  достаточна  и  накладные
		// расходы на загрузку данных из L2 пренебрежительго малы
		x += *(int *)((char *)p1 + _p1); if ((_p1 += 4) > BLOCK1_SIZE) _p1 = 0;

		// даем процессору команду на загрузку данных блока BLICK2 в L1-кэш,
		// в обход L2-кэша, что во-первых, позволяет избавится  от  ожидания
		// загрузки   из   медленной   оперативной   памяти,  а,  во-вторых,
		// предотвращает вытестение данных блока BLOCK1 из L2-кэша
		_prefetchnta((char *)((char *)p2 + a + STEP_SIZE*6));
		//											^^^^
		// обратите внимание: предвибираются  данные, к  которым  произойдет
		// обращение только через шесть итераций цикла. Почему  именно  так?
		// дело в том, что латентность  подсистемы  памяти  превышает  время
		// выполнения дной итерации цикла;загружая данные следующих итераций
		// мы  теряем лишь 6 первых итераций,  а не  через шесть  интераций,
		// как может показаться в начале, т.е. этот прием  вполне  законен и
		// обеспечивает максимальный прирост быстродействия
		// (подробнее см. "Планирование дистанции предвыборки")
		
		//				* * * обрабатываем блок BLOCK1 * * *
		// Теперь данные загружаются из L1-кэша!
		x += *(int *)((char *)p2 + a);
		x += *(int *)((char *)p2 + a + 4);
		x += *(int *)((char *)p2 + a + 8);
		x += *(int *)((char *)p2 + a + 12);
		x += *(int *)((char *)p2 + a + 16);
		x += *(int *)((char *)p2 + a + 20);
		x += *(int *)((char *)p2 + a + 24);
		x += *(int *)((char *)p2 + a + 28);
	}
	return x;
}

/*----------------------------------------------------------------------------
 *
 *				ТЕСТ C ПРЕДВЫБОРКОЙ prefetcht0 (Mem -> L2 -> L1)
 *													(оптимизированный вариант)
 *
----------------------------------------------------------------------------*/
int have_prefetcht0(int *p1, int *p2)
{
	int x = 0;
	int _p2, _p1 = 0;

	for(_p2 = 0; _p2 < BLOCK2_SIZE; _p2 += STEP_SIZE)
	{
		//				* * * обрабатываем блок BLOCK1 * * *
		// предвыборка в L1-кэш  не  нужна, т.к.  производительность L2-кэша
		// (в котором и находится данный блок) вполне достаточна и накладные
		// расходы на загрузку данных из L2 пренебрежительго малы
		x += *(int *)((char *)p1 + _p1); if ((_p1 += 4) > BLOCK1_SIZE) _p1 = 0;

		// ради эксперимента делаем предзагрузку данных в L1 и L2 кэш
		// это по-прежнему устряняет простои на загрузку данных из медленной
		// оперативной памяти, но засоряет L2 кэш, который  занят интенсивно
		// используемым блоком  BLOCK1;  и  вследствие  этого  эффективность
		// предвыборки чуть-чуть падает; "чуть-чуть" потому, что вытесняется
		// всего лишь одна линейка на каждую итерацию
		_prefetcht0((char *)((char *)p2 + a + STEP_SIZE*6));

		//				* * * обрабатываем блок BLOCK1 * * *
		// Теперь данные загружаются из L1-кэша!
		x += *(int*) ((char *)p2 + a);
		x += *(int *)((char *)p2 + a + 4);
		x += *(int *)((char *)p2 + a + 8);
		x += *(int *)((char *)p2 + a + 12);
		x += *(int *)((char *)p2 + a + 16);
		x += *(int *)((char *)p2 + a + 20);
		x += *(int *)((char *)p2 + a + 24);
		x += *(int *)((char *)p2 + a + 28);
	}
	return x;
}


/*----------------------------------------------------------------------------
 *
 *				ТЕСТ C ПРЕДВЫБОРКОЙ prefetcht1 (Mem -> L2)
 *													(оптимизированный вариант)
 *
----------------------------------------------------------------------------*/
int have_prefetcht1(int *p1, int *p2)
{
	int x = 0;
	int _p2, _p1 = 0;

	for(_p2 = 0; _p2 < BLOCK2_SIZE; _p2 += STEP_SIZE)
	{
		//				* * * обрабатываем блок BLOCK1 * * *
		// предвыборка в L1-кэш  не  нужна, т.к.  производительность L2-кэша
		// (в котором и находится данный блок) вполне достаточна и накладные
		// расходы на загрузку данных из L2 пренебрежительго малы
		x += *(int *)((char *)p1 + _p1); if ((_p1 += 4) > BLOCK1_SIZE) _p1 = 0;

		// ради эксперимента выполняем предвыборку в один лишь L2 - кэш; это
		// самая   неэффективная   стратегия  предвыборки!  мало  того,  что
		// процессору  придется  некотрое время ждать пока данные из L2 кэша
		// не загрузятся в L1 кэш, так еще из L2 кэша  вытесняются  полезные
		// данные! (разумеется, это  не  означает,  что  prefetch1  "плохая"
		// инструкция, просто в _данном_ случае, такая стратегия оказывается
		// самой неоптимальной)
		_prefetcht1((char *)((char *)p2 + a + STEP_SIZE*6));

		//				* * * обрабатываем блок BLOCK1 * * *
		// данные находятся в L2 кэше и приходится несколько  тактов  стоять
		// в ожидании пока они не загрузятся
		x += *(int *)((char *)p2 + a);
		x += *(int *)((char *)p2 + a + 4);
		x += *(int *)((char *)p2 + a + 8);
		x += *(int *)((char *)p2 + a + 12);
		x += *(int *)((char *)p2 + a + 16);
		x += *(int *)((char *)p2 + a + 20);
		x += *(int *)((char *)p2 + a + 24);
		x += *(int *)((char *)p2 + a + 28);
	}
	return x;
}

main()
{
	int *p1, *p2;

	// TITLE
	PRINT("= = = memory optimization using prefetch (prefetch type) = = =\n");
	PRINT_TITLE;

	// выделяем память
	p1 = (int *) _malloc32(BLOCK1_SIZE);
	p2 = malloc(BLOCK2_SIZE);

	A_BEGIN(1);
		no_prefetch(p1,p2);
	A_END(1);

	A_BEGIN(2)
		have_prefetchnta(p1, p2);
	A_END(2);
	
	A_BEGIN(3)
		have_prefetcht0(p1, p2);
	A_END(3);

	A_BEGIN(4)
			have_prefetcht1(p1, p2);
	A_END(4);

	Lx_OUT("PreFetchNTA",Ax_GET(1),Ax_GET(2));
	Lx_OUT("PreFetchT0 ",Ax_GET(1),Ax_GET(3));
	Lx_OUT("PreFetchT1 ",Ax_GET(1),Ax_GET(4));

}


